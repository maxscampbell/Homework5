---
title: "Homework 5: Models and Model Comparisons"
author: "Max Campbell"
format: pdf
---

## Task 1: Conceptual Questions

* What is the purpose of using cross-validation when fitting a random forest model?

Generally, when fitting a random forest model, we want to randomly subset predictors to make sure that no predictor overwhelms the model and significantly effects the output. As such, we need to choose how many predictors are subset each time. This is where cross-validation comes into play. By implementing cross-validation and obtaining the most optimized tuning parameter we can improve our predictions.

* Describe the bagged tree algorithm.

In the bagged tree algorithm, we begin by bootstrapping some number of samples $B$. From there, we can fit a tree to each sample to have $B$ number of trees. Then, from there, we can find response for each tree and then combine them to aggregate a final prediction. In practice, this combination is typically the average of all the sample predictions. 

* What is meant by general linear model?

A general linear model is the family of models that we use more conventionally. For example, SLRs, MLRs, ANOVA and ANCOVA models all fall under this family (so long as all effects are fixed and not random). The main characteristic of these models is assuming that the response variable follows a normal distribution.

* When fitting a multiple linear regression model, what does adding an interaction term do? That is, what does it allow the model to do differently as compared to when it is not included in the model?

The main reason to include an interaction variable is to allow the effect of one variable to be dependent on another variable. For example, in a plant growth study, the amount of sunlight and temperature may be heavily related to one another, so an interaction term may be beneficial to include in the model.

* Why do we split our data into a training and test set?

Splitting the model into a training set and test set allows us to see how well the model may perform if it was tasked with prediction future observations. By having test data, we can compare a model's predictions to the actual outcome to measure performance.

## Task 2: Data Prep

### Packages and Data

```{r}
#| message: FALSE
#| warning: FALSE

library(tidyverse)
library(tidymodels)
library(caret)
library(yardstick)
library(glmnet)

heart <- as_tibble(read.csv("heart.csv", header = TRUE))
```

### Question 1

```{r}
summary(heart)
```

The `HeartDisease` variable is quantitative. This does not make sense, since an individual either has a heart disease or they don't, so it is more intuitive to consider this a categorical variable.

### Question 2

```{r}
#Subset dataset into relevant data of the correct type

heart_new <- heart |>
  mutate(HasHeartDisease = as.factor(HeartDisease)) |>
  select(-c(ST_Slope, HeartDisease))

#Change names of factor levels in HasHeartDisease to improve plot outputs later down the line

levels(heart_new$HasHeartDisease) <- c("No", "Yes")
```

## Task 3: EDA

### Question 1

```{r}
#Plot Age vs. Heart Rate, grouped by Heart Disease status

ggplot(data = heart_new, aes(x = MaxHR, y = Age, color = HasHeartDisease)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE, formula = y ~ x) +
  labs(x = "Maximum Heart Rate", y = "Age", 
       title = "Age vs. Heart Rate and Presence of Heart Disease", color = "Has Heart Disease") +
  scale_color_manual(values = c("orange", "royalblue"))
```

### Question 2

Based on our output above, it looks like the presence of heart disease makes a sizable impact on the regression line. As such, an interaction term appears necessary as heart disease may have a notable effect on an individuals maximum heart rate.

## Task 4: Testing and Training

```{r}
#Set random seed so results are reproducible
set.seed(101)

#Split data into a testing set and training set
heart_split <- initial_split(heart_new, prop = 0.8)
test <- testing(heart_split)
train <- training(heart_split)
```

## Task 5: OLS and LASSO

### Question 1

```{r}
#
ols_mlr <- lm(Age ~ MaxHR + HasHeartDisease + MaxHR:HasHeartDisease, data = train)
summary(ols_mlr)
```

### Question 2

```{r}
# Using tidymodels functionality, calculate the RMSE
ols_mlr_rmse <- yardstick::rmse_vec(test$Age, predict(ols_mlr, newdata = test))
ols_mlr_rmse
```

### Question 3

```{r}
#Create a 10-fold CV
train_folds <- vfold_cv(train, 10)

#Create an interaction model using a LASSO parameter
LASSO_recipe <- recipe(Age ~ MaxHR + HasHeartDisease, data = train) |>
  step_dummy(HasHeartDisease) |>
  step_normalize(MaxHR) |>
  step_interact(~MaxHR:starts_with("HasHeartDisease_"))

#Display recipe properties
LASSO_recipe
```

### Question 4

```{r}
#Set spec and workflow
LASSO_spec <- linear_reg(penalty = tune(), mixture = 1) |>
  set_engine("glmnet")

LASSO_workflow <- workflow() |>
  add_recipe(LASSO_recipe) |>
  add_model(LASSO_spec)

#Set grid
LASSO_grid <- LASSO_workflow |> #Using 200 as it seems to be a reasonable value
  tune_grid(resamples = train_folds, grid = grid_regular(penalty(), levels = 200)) 

#Get the model with the best RMSE and fit it to our training data
rmse_best_fit <- LASSO_grid |>
  select_best(metric = "rmse")

LASSO <- LASSO_workflow |>
  finalize_workflow(rmse_best_fit) |>
  fit(train)

#Report results
tidy(LASSO)
```

### Question 5

The model coefficients in the LASSO model are very different from the MLR model, so we might expect the RMSE to be different since the observations did not change.

### Question 6

```{r}
ols_mlr_rmse #Ordinary Least Squares RMSE

#LASSO RMSE
LASSO |>
  predict(test) |>
  pull() |>
  rmse_vec(truth = test$Age)
```

The results are very similar! The LASSO model has the slightest edge in this run, but both models are performing essentially the same.

### Question 7

We standardized the values for our LASSO model, but did not do so for the MLR model, which is likely the biggest factor in why our coefficients are so different. As such, the line of best fit likely falls within a similar spot relative to the observations in both datasets, and thus our RMSE would be similar as well.

## Task 6: Logistic Regression